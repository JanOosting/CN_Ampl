---
title: "CN_Version2"
author: "w. plugge"
date: "6/5/2015"
output: html_document
---

```{r setup, echo=FALSE, message=FALSE}
# message = false => no info about loading packages
require(knitr)
#opts_knit$set(root.dir = '/home/wplugge/BAM.files/')


library(grid)
library(ggplot2)
library(dplyr)
library(tidyr)

library(quantsmooth)


# awk -v OFS='\t' '{gsub("CHP2_", "", $4)} {print $1, $2, $3, 0, $4}' CHP2-rmprimers.bed > primers.bed
# bedtools sort -i primers.bed > sorted.primers.bed


```

-----------------------------------------------------
 CN Analysis
-----------------------------------------------------
Copy number variation analysis of amplicons    
1) per base coverage of overlapping amplicon regions are divided by the number of overlapping amplicons     
2) calculate per base median of an amplicon       
3) divide amplicon value (as retrieved at step 2) by median sample      
4) divide amplicon value (as retrieved at step 3) by the median amplicon value accross samples       
5) median polishing -> repeat step 3 and 4        




Using bedtools calculate per base coverage of all amplicons   

```{r computeCoverage, echo=FALSE}
# File with amplicon regions
# amplFile=sorted.unique.complete.PolypSeq-withAMPL.bed 

#if(!dir.exists("per.base.coverage")) {
#system('amplFile=/home/wplugge/R/additional.pool/sorted.primers.bed; mkdir per.base.coverage; for fileName in /home/wplugge/R/additional.pool/433/test.1#.file/*.bam; do output=`echo "$fileName" | sed s/bam/cov/g`; echo "$output"; coverageBed -abam "$fileName" -b $amplFile -d |  awk \'{print $1"_"$2"_"$#3,$8}\' > per.base.coverage/"$output"; done;')
#}





# commandline
# -v at awk is added, not similar as dinas code above
#amplFile=/home/wplugge/R/additional.pool/primerPool.sorted.primers.bed; 
#mkdir per.base.coverage; 
#for fileName in *.bam; do coverageBed -abam "$fileName" -b $amplFile -d |  awk -v x="$fileName" '{print x,$1"_"$2"_"$3,$5,$6,$7}' >> new.base.coverage.panel_439.txt ; done;
```





```{r process_bedtools_coverage_output, echo=FALSE, message=FALSE} 
#PROCESSING FILES AND QUALITY CONTROL
#-----------------------------------------------------
# PROCESSING FILES AND QUALITY CONTROL

# Processing files retrieved after using bedtools coverage. Files contain per base pair coverage of all amplicons. Data from these files (of all   samples) will be merged into one table, which has the following structure:
# amplicon                sample1 sample2
# 10_89624270_89624359    140     144  
# Furthermore, this step includes a quality control step where samples with a median coverage lower than 10 are excluded from further analysis
#-----------------------------------------------------


###!!!! Add cutoff value for samples!!!!!!!!!!!!!


#input has to have this format:
# sample -   genomic position -     ampl.name combined with pool -number coverage
# 151110.bam chr1_42844195_42844317 rs7514030_p1                  886


outputFileTable="/home/wplugge/R/additional.pool/439/new.439_CNV_analysis.txt"
pool.coverage=read.table("/home/wplugge/R/additional.pool/439/new.base.coverage.panel_439.txt")
colnames(pool.coverage)=c("sample", "chr", "ampl.start", "ampl.stop", "amplicon", "index", "coverage")



```




```{r adjust_coverage_overlapping_amplicons, echo=FALSE, warning=FALSE}

#-----------------------------------------------------
# ADJUST COVERAGE OVERLAPPING AMPLICONS - STEP 2: IDENTIFY OVERLAPPING AMPLICONS & DIVIDE COVERAGE BY NUMBER OF AMPLICONS OVERLAPPING THAT POSITION
#-----------------------------------------------------

# This code needs to be checked with overlapping amplicon regions!!!!!!!!!!!!!!!!!!

# group by sample and genomic position to count the occurence of each position. number of times a position occurs is 

pool.coverage = pool.coverage %>%  
  mutate(genomic.pos=ampl.start+index-1) %>% # Calculate genomic position = start ampl + bedtools index -1 (=start at start)
  group_by(sample, genomic.pos) %>%  # counted. Coverage per base pair position is divided by the number of times a position occured
  mutate(count.occurence=n() , corr.coverage=coverage/count.occurence)  %>% # How often does a pos per ampl occur / normalize  
  group_by(sample, amplicon) %>%                          # Group data by sample and amplicon (=ampl-id of location ampl)
  mutate(ampl.median = median(as.numeric(corr.coverage))) %>%         # Calculate median corrected coverage of each ampl per sample
  select(sample, chr, ampl.start, ampl.stop, amplicon, ampl.median) %>%  # select columns for further usage
  unique() %>%                                             # Rm duplicated rows
  #filter(!grepl("^AME", amplicon))
  filter(!grepl("^rs", amplicon)) %>%
  group_by(sample) %>% #part=Identify samples with a median amplicon coverage of 20 + Add 1 to coverage (for log transformation)
  mutate(median.coverage=ifelse(median(ampl.median) < 20, "low_median_cov", "approved_cov"), ampl.median=ampl.median+1)

# data used for plotting. first amplicon median is determined (from the per base coverage). Using this data the median of the sample
# is determined. Since we added 1 to each coverage (for log10 transformation) i substract 1 from each value to get the original value
sample.median=pool.coverage %>% group_by(sample) %>%
  mutate(sample.median=median(ampl.median)-1) %>%
  select(sample, sample.median) %>%
  unique()

# Within sample normalization, different primerpools are taken into account
within.sample.normalization =  pool.coverage %>%
    # Extract pool numbers and rm pool number from amplicon name, create gene name
    mutate(pool_nr= sub("^.*_.*(_.*)", "\\1", amplicon), pool_nr=sub("^.*_(.*)", "\\1", pool_nr)) %>%
    mutate(amplicon=sub("(^.*_.*)_.*", "\\1", amplicon), gene=sub("_.*", "", amplicon)) %>% 
    group_by(sample, pool_nr) %>%
    mutate(within.median.corr=ampl.median/median(ampl.median)) %>% #ampl median divided by sample median of the same primer pool
    ungroup() %>% # otherwise you will automatically select "pool_nr", since this was grouped with sample
    select(sample, chr, ampl.start, ampl.stop, amplicon, gene, median.coverage, within.median.corr)




# Samples that are already marked as low median coverage are excluded from normalization
initial.between.sample.normalization = within.sample.normalization %>% 
  group_by(amplicon, median.coverage) %>%
  # Calculate median of amplicons between approved samples
  mutate(temp.between.median=ifelse(median.coverage=="approved_cov", median(within.median.corr), as.numeric(NA))) %>%
  group_by(amplicon) %>%
  # Assign ampl median value of approved samples to discarded samples, so all ampl have the same median correcting factor
  mutate(between.median=max(temp.between.median, na.rm=TRUE)) %>% 
  # Between sample normalization
  mutate(between.median.corr=within.median.corr/between.median) %>%
  # Select columns (so some are discarded during this process)
  select(sample, chr, ampl.start, ampl.stop, amplicon, gene, median.coverage, within.median.corr, between.median.corr)



# Per gene standard deviation divided by the mean of the gene, followed by average the calculated value of one sample
avg_stdev_complete = initial.between.sample.normalization %>% 
  filter(!grepl("^AME", amplicon)) %>%
  filter(!grepl("^low_median_cov", median.coverage)) %>%
  group_by(sample,gene) %>% 
  mutate(mean.gene = mean(as.numeric(between.median.corr)), vc.gene = sd(as.numeric(between.median.corr), na.rm=TRUE)/mean.gene) %>% 
  select(sample, median.coverage, gene, vc.gene) %>% 
  unique() %>% 
  group_by(sample) %>%
  mutate(average.stdev=mean(as.numeric(vc.gene), na.rm=TRUE)) %>%
  select(sample, average.stdev) %>% 
  unique()  #%>%
  #filter(average.stdev>0.3) # samples that have a standard deviation (of the mean) bigger than 0.3 (our set cutoff) are not included in determining the median coverage between samples of that amplicon. These samples still will be normalized using the selected median

avg_stdev=avg_stdev_complete[which(avg_stdev_complete$average.stdev > 0.3),]




# samples that have a standard deviation (of the mean) bigger than 0.3 (our set cutoff) are not included in determining the median
# coverage between samples of that amplicon. These samples still will be normalized using the selected median
#sample.ex.norm=avg_stdev[which(avg_stdev$average.stdev >0.3),] # I know i can do this at the step above using filter, but for now i wanted to keep the whole list containing stdev for all samples
#print("The following samples were excluded:")
#print.data.frame(avg_stdev)




# Calculate the median of each amplicon of samples with a stdev <= 0.3. This median is used to do a between sample normalization of
# amplicons and normalize data using values derived from approved samples. 
between.sample.normalization = within.sample.normalization %>% 
  # Add column that indicated which samples have a higher stdev than the set threshold of 3
  mutate(stdev.approved=ifelse(sample %in% avg_stdev$sample, "above_threshold", "approved_stdev")) %>%
  # Add column that, based on median coverage and stdev, indicated which samples are discarded and approved
  mutate(sample.consider=ifelse(median.coverage=="low_median_cov" | stdev.approved=="above_threshold", "discarded", "approved")) %>%
  group_by(amplicon, sample.consider) %>%
  # Calculate median of amplicons between approved samples
  mutate(temp.between.median=ifelse(sample.consider=="approved", median(within.median.corr), as.numeric(NA))) %>%
  group_by(amplicon) %>%
  # Assign ampl median value of approved samples to discarded samples, so all ampl have the same median correcting factor
  mutate(between.median=max(temp.between.median, na.rm=TRUE)) %>% 
  # Between sample normalization followed by log10 transformation
  mutate(between.median.corr=within.median.corr/between.median, log10=log10(between.median.corr)) %>%
  # Select columns (so some are discarded during this process)
  select(sample, chr, ampl.start, ampl.stop, amplicon, gene, within.median.corr, sample.consider, between.median.corr, log10)



# quanthsmooth
data.smoothing= between.sample.normalization %>% 
    group_by(sample, gene) %>%
    mutate(quant.smooth=quantsmooth(log10))


# Calculate confidence interval for smoothed values

CI = data.smoothing %>% 
  #filter(!sample %in% sample.ex.norm$sample) %>% # samples with stdev > 3.0 are removed 
  group_by(gene, sample.consider) %>% 
  mutate(q_median=ifelse(sample.consider=="approved", median(as.numeric(quant.smooth)), as.numeric("NA"))) %>% # warning! (suppressWarnings()??)
  mutate(q_mad=ifelse(sample.consider=="approved", mad(as.numeric(quant.smooth)), as.numeric("NA"))) %>% 
  #mutate( q_median=median(as.numeric(quant.smooth)),q_mad=mad(as.numeric(quant.smooth)))  %>%
  mutate(LCI=q_median+qnorm(0.005)*q_mad, UCI=q_median+qnorm(0.995)*q_mad) %>%
  group_by(gene) %>%
  mutate(LCI=max(LCI, na.rm=TRUE), UCI=max(UCI, na.rm=TRUE))
         



# Create table that provides overview of which amplicons are associated with deleted/amplified (partial) genes
CNV.table=CI %>% 
  ungroup() %>%  # Actions above kept data grouped, not required now
  mutate(CNV = ifelse(quant.smooth < LCI, "deletion", ifelse(quant.smooth > UCI, "amplification","NA"))) %>%
  filter(!CNV=="NA") %>%
  select(sample, amplicon, sample.consider, quant.smooth, LCI, UCI, CNV)

write.table(CNV.table, outputFileTable, sep="\t", quote=FALSE, row.names=FALSE )

print("The following samples were excluded:")
print(unique(CI[which(CI$sample.consider=="discarded"),1]))

```


Only samples with a stdev < 0.3 were included in determining the confidence interval per gene. 
```{r, echo=FALSE, fig.width=15, fig.height=20, warning=FALSE}

# remove pool number from amplicon name (maybe do that more above??) (plotting needs group_by??)
#CI=CI %>% group_by(sample) %>% 
#  mutate(ampl.new=sub("_p.*", "", amplicon))

CI$amplicon = factor(CI$amplicon, levels = CI$amplicon) # do no reorder labels
CI$gene = factor(CI$gene, levels = CI$gene)



a=ggplot(CI, aes(x=amplicon, y=quant.smooth , color=gene, 
                                                 shape=ifelse((quant.smooth >= LCI & quant.smooth <= UCI),"A", "B"))) + 
  geom_rect(aes(fill = sample.consider, color=c("pink", "red")), xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, alpha = 0.1) +
  geom_point(size=1) +
  scale_color_manual(values=rep(c("dodgerblue4", "darkolivegreen4","darkorchid3", "orange"),length.out=length(unique(CI$gene))), guide=FALSE) +
  scale_shape_manual(guide=FALSE, values=c(16, 8)) +   #define shapes
  facet_wrap(~sample, ncol = 1)  + #, scales="free_x")
  theme_bw() +
  theme(axis.text.x=element_text(angle=90, vjust = 1, size=6))
plot(a)




```

# SAMPLE MEDIAN 

```{r, echo=FALSE, fig.width=8, fig.height=8, warning=FALSE}

plot(density(as.numeric(sample.median$sample.median)), main="", xlab="Median sample coverage")

```


# STANDARD DEVIATION (per gene(stdev/mean) => mean sample)

```{r, echo=FALSE, fig.width=8, fig.height=8, warning=FALSE}

plot(density(as.numeric(avg_stdev_complete$average.stdev)), main="", xlab="Standard deviation")


# Add plot for stdev
# see email of Dina for new data
# something wrong with CI??
# create html and show dina, gene is still not significant
```






